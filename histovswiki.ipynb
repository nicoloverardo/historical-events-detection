{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('base': conda)",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "75e1510848ff81b2a8a3022c3bfac472ed28a49a56e1422a056d525171f2408b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# NER Histo vs NER Wiki"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf2crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/mhc/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/content/drive/My Drive/Colab Notebooks/mhc/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from model import BilstmCrf\n",
    "from text import PreProcessing\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from p_tqdm import p_map\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/wiki/wiki.csv\", sep=\"|\")\n",
    "df.Abstract = df.Abstract.parallel_apply(lambda x: PreProcessing.small_clean(x))\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data):\n",
    "    sentences, labels, sentence, tag = [], [], [], []\n",
    "\n",
    "    for text in data:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        for sent in doc.sents:\n",
    "            for word in sent:\n",
    "                sentence.append(word.text)\n",
    "                if word.ent_type_ is not \"\":\n",
    "                    tag.append(word.ent_iob_+\"-\"+word.ent_type_)\n",
    "                else:\n",
    "                    tag.append(word.ent_iob_)\n",
    "        \n",
    "            sentences.append(\" \".join(sentence))\n",
    "            labels.append(\" \".join(tag))\n",
    "\n",
    "            sentence, tag = [], []\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1791/1791 [00:54<00:00, 32.74it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = parse_data(tqdm(df.Abstract.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to map the ents of spacy to histo"
   ]
  }
 ]
}