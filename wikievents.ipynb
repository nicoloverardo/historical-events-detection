{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "wikievents.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0gTFjXqBC3wq"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp1C-QrsC6Ug"
      },
      "source": [
        "# Event detection from Wikipedia pages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdGlzS0yB-oD",
        "outputId": "bf2cb173-8784-4fcd-d36e-b7dd2d1b7b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "source": [
        "!pip install pandarallel sparql-client p_tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandarallel\n",
            "  Downloading https://files.pythonhosted.org/packages/62/30/3c2c89597bb01b75779432d469562a235c47538cf96152ed01d695ad41ce/pandarallel-1.5.1.tar.gz\n",
            "Collecting sparql-client\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/33/e91a33bdb637cbf20035885de5a4e3d6439055ec8d950d06b466e3e379b6/sparql-client-3.8.zip\n",
            "Collecting p_tqdm\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/c4/ce6abe2fa3868b1ea9216a81522a9ece36f47bdbb966f8f31f76e2967178/p_tqdm-1.3.3.tar.gz\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from pandarallel) (0.3.2)\n",
            "Collecting eventlet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/62/5530eb05ecd4bc2680bf6f753560901e84bd4f7ba86a1da45e7accdfec7b/eventlet-0.29.0-py2.py3-none-any.whl (223kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sparql-client) (1.15.0)\n",
            "Collecting dnspython<2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d3/3aa0e7213ef72b8585747aa0e271a9523e713813b9a20177ebe1e939deb0/dnspython-1.16.0-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from p_tqdm) (4.41.1)\n",
            "Collecting pathos\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/ea/b2cf3a6561fc5deb64de8ae0af5e3e4e2db03ca588cb7415efce4a8de26e/pathos-0.2.6.zip (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 14.3MB/s \n",
            "\u001b[?25hCollecting monotonic>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
            "Collecting greenlet>=0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d0/532e160c777b42f6f393f9de8c88abb8af6c892037c55e4d3a8a211324dd/greenlet-0.4.17-cp36-cp36m-manylinux1_x86_64.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[?25hCollecting ppft>=1.6.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/fb/fa21f6e9aedc4823448473ed96e8eab64af1cb248c18165f045a90e1c6b4/ppft-1.6.6.2.zip (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 18.7MB/s \n",
            "\u001b[?25hCollecting pox>=0.2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/0c/ec447fb0ed88bc1c09bf0dadf00e40ea05fda17e841d15bb351a52d9e192/pox-0.2.8.zip (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 16.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess>=0.70.10 in /usr/local/lib/python3.6/dist-packages (from pathos->p_tqdm) (0.70.10)\n",
            "Building wheels for collected packages: pandarallel, sparql-client, p-tqdm, pathos, ppft, pox\n",
            "  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandarallel: filename=pandarallel-1.5.1-cp36-none-any.whl size=17126 sha256=b662332e9bac2692fa489543c9abbb4e7755a8104fb0d83ce3c85687099c57e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/c8/e5/d43fa63105ce1dd22f4df51bc2edfefd54d92ce64f25326314\n",
            "  Building wheel for sparql-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sparql-client: filename=sparql_client-3.8-cp36-none-any.whl size=13666 sha256=6403c6d9ec4302a84ee6dc04d7fc839f10682683c6dc5dc885bf8ef3c1b19f5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/c6/b3/dc96bcb728d766c48ac7771591c063edd598ecaf13ec30552c\n",
            "  Building wheel for p-tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for p-tqdm: filename=p_tqdm-1.3.3-cp36-none-any.whl size=3988 sha256=f3aa78cad495004c15f2584af0c68570bfdcb7a6c65b37b85868ba8fc68ca6f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/26/f7/18d7dcd10ebd3f81fab3f52e07c61b5771cd21c29f69c7a0e9\n",
            "  Building wheel for pathos (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathos: filename=pathos-0.2.6-cp36-none-any.whl size=77674 sha256=8ce1deab13b69f3021e29a50aa7a493b4c6d0f13008d9f2ed24275f4494548fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/e8/c8/04cdd0c4bc6fbce35f642fc004244228916daae74bb0f482da\n",
            "  Building wheel for ppft (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ppft: filename=ppft-1.6.6.2-cp36-none-any.whl size=64743 sha256=74b3352a1fb7bc2e0152d8dcafc524aec440d6867e54cd22e720b7b7ce89faf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/d2/2d/0ee21ede61786bb13247dbc69079373fd500c2bb0481913084\n",
            "  Building wheel for pox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pox: filename=pox-0.2.8-cp36-none-any.whl size=28290 sha256=fb089793e144b080f8898e3406d255739f108de0ecfc5a54e50b89b272564f4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/ed/ce/a93103746b327e18bffaeb99ba0d57a88b392f31d719cea700\n",
            "Successfully built pandarallel sparql-client p-tqdm pathos ppft pox\n",
            "Installing collected packages: pandarallel, dnspython, monotonic, greenlet, eventlet, sparql-client, ppft, pox, pathos, p-tqdm\n",
            "Successfully installed dnspython-1.16.0 eventlet-0.29.0 greenlet-0.4.17 monotonic-1.5 p-tqdm-1.3.3 pandarallel-1.5.1 pathos-0.2.6 pox-0.2.8 ppft-1.6.6.2 sparql-client-3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdCOiPH8mrJM",
        "outputId": "ae720b66-7faa-40ba-b6cd-1c4662561134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVgX29unmrJQ"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/mhc/')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7nCKWEJmrJU",
        "outputId": "0059af13-3048-4f38-e30b-de42134e6ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/mhc/\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/mhc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_DZiM6HBUUY",
        "outputId": "ad65ab90-1ba7-4dda-866f-c173f4467724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63ySqF6tA-R7",
        "outputId": "6a3c9af7-154c-437c-d52b-faf4f91beca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from text import PreProcessing\n",
        "from buildGloveVocab import GloveVocab\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "from tqdm import tqdm\n",
        "import multiprocessing as mp\n",
        "from multiprocessing import Pool\n",
        "\n",
        "from p_tqdm import p_map\n",
        "\n",
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize(progress_bar=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Pandarallel will run on 8 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gTFjXqBC3wq"
      },
      "source": [
        "## Download Wikipedia pages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKUq-TigCkMi"
      },
      "source": [
        "from wikiapi import WikiWrapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV55Dj40A-R_"
      },
      "source": [
        "q_hist = (\n",
        "    \"\"\"\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    SELECT DISTINCT ?Event_1\n",
        "    WHERE { ?Event_1 a dbo:Event .\n",
        "            ?Event_1 a dbo:MilitaryConflict . }\n",
        "\n",
        "    LIMIT 1000\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "q_nonhist_1 = (\n",
        "    \"\"\"\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    SELECT DISTINCT ?Artist_1\n",
        "    WHERE { ?Artist_1 a dbo:Artist . }\n",
        "\n",
        "    LIMIT 500\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "q_nonhist_2 = (\n",
        "    \"\"\"\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    SELECT DISTINCT ?Animal_1\n",
        "    WHERE { ?Animal_1 a dbo:Animal . }\n",
        "\n",
        "    LIMIT 500\n",
        "    \"\"\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "que8jlOcA-SC"
      },
      "source": [
        "hist_events_name = WikiWrapper.download_pages_name(q_hist)\n",
        "non_hist_events_name = WikiWrapper.download_pages_name(q_nonhist_1)\n",
        "non_hist_events_name = non_hist_events_name + WikiWrapper.download_pages_name(q_nonhist_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WebbplYTA-SF"
      },
      "source": [
        "df = pd.DataFrame(hist_events_name, columns=[\"Name\"])\n",
        "df[\"Abstract\"] = \"\"\n",
        "df[\"Label\"] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXW2Uf_LA-SJ"
      },
      "source": [
        "df1 = pd.DataFrame(non_hist_events_name, columns=[\"Name\"])\n",
        "df1[\"Abstract\"] = \"\"\n",
        "df1[\"Label\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yzfNGG5A-SM"
      },
      "source": [
        "df = pd.concat([df, df1])\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XvAdqttA-SP"
      },
      "source": [
        "df[\"Abstract\"] = df.parallel_apply(WikiWrapper.get_extract, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O74yk9P6A-ST"
      },
      "source": [
        "df.dropna(subset=[\"Abstract\"], inplace=True)\n",
        "df.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RunTn0RLA-SW"
      },
      "source": [
        "df[\"Abstract\"] = df[\"Abstract\"].parallel_apply(lambda x: x.replace(\",\", \"\").replace(\"|\", \"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXMV-tV_A-SZ"
      },
      "source": [
        "df.to_csv(\"data/wiki/wiki.csv\", index=False, sep=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUmZW6S0CzJa"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxwtSmmvA-Se"
      },
      "source": [
        "df = pd.read_csv(\"data/wiki/wiki.csv\", sep=\"|\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obur-P-FA-Sh"
      },
      "source": [
        "df.Abstract = df.Abstract.parallel_apply(lambda x: PreProcessing.cleanText(x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L5kXPl5A-Sk"
      },
      "source": [
        "df.drop(columns=[\"Name\"], inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOiS-42EA-Sy"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.Abstract.values, df.Label.values, test_size=0.2, random_state=42, stratify=df.Label.values)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2A8lnTDMzMe"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkZErV1eK1H3"
      },
      "source": [
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(X_train).batch(BATCH_SIZE)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc4nY2_ORq9n"
      },
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJUfrSlZkp6t"
      },
      "source": [
        "Skip the two cells below if you have already a compressed representation of the embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOuakEMhfuup",
        "outputId": "135d4d45-c5f0-4afb-cf93-bbe814e0b4cf"
      },
      "source": [
        "path_to_glove_file = Path(\"wordemb/glove.840B.300d.txt\")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i % 100000 == 0:\n",
        "            print('- At line {}'.format(i))\n",
        "\n",
        "        line = line.strip().split()\n",
        "\n",
        "        if len(line) != 300 + 1:\n",
        "            continue\n",
        "\n",
        "        word = line[0]\n",
        "        coefs = \" \".join(line[1:])\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- At line 0\n",
            "- At line 100000\n",
            "- At line 200000\n",
            "- At line 300000\n",
            "- At line 400000\n",
            "- At line 500000\n",
            "- At line 600000\n",
            "- At line 700000\n",
            "- At line 800000\n",
            "- At line 900000\n",
            "- At line 1000000\n",
            "- At line 1100000\n",
            "- At line 1200000\n",
            "- At line 1300000\n",
            "- At line 1400000\n",
            "- At line 1500000\n",
            "- At line 1600000\n",
            "- At line 1700000\n",
            "- At line 1800000\n",
            "- At line 1900000\n",
            "- At line 2000000\n",
            "- At line 2100000\n",
            "Found 2195876 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6FpZzN1fuus",
        "outputId": "260bd02f-033a-4039-d489-062e4a88257b"
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 300\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embeddings = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embeddings[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
        "\n",
        "np.savez_compressed(\"data/wiki/glove_wiki.npz\", embeddings=embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20000/20000 [00:00<00:00, 216934.23it/s]\n",
            "Converted 15502 words (4498 misses)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BzvnhxJkyza"
      },
      "source": [
        "Reload your embedding matrix here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bFycUQwfuux"
      },
      "source": [
        "embeddings = np.load(\"data/wiki/glove_wiki.npz\")['embeddings']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxO1zf6QRs1o"
      },
      "source": [
        "X_train = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
        "X_val = vectorizer(np.array([[s] for s in X_val])).numpy()\n",
        "X_test = vectorizer(np.array([[s] for s in X_test])).numpy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Izxrj9gA-S8"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(None,), dtype=\"int64\"),\n",
        "    tf.keras.layers.Embedding(len(voc) + 2, 300, embeddings_initializer=tf.keras.initializers.Constant(embeddings), trainable=False),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihbgCCI0Nr0Q",
        "outputId": "16f29613-b977-4f28-84e2-7733b86d0e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 300)         6000600   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, None, 256)         439296    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 6,867,161\n",
            "Trainable params: 866,561\n",
            "Non-trainable params: 6,000,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtFYVvYZA-S_",
        "outputId": "65e36965-6d86-4505-97a8-40246201806a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "18/18 [==============================] - 2s 129ms/step - loss: 0.2249 - accuracy: 0.8900 - val_loss: 0.0973 - val_accuracy: 0.9652\n",
            "Epoch 2/20\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0835 - accuracy: 0.9467 - val_loss: 0.0536 - val_accuracy: 0.9512\n",
            "Epoch 3/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0518 - accuracy: 0.9581 - val_loss: 0.0498 - val_accuracy: 0.9721\n",
            "Epoch 4/20\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0523 - accuracy: 0.9747 - val_loss: 0.0495 - val_accuracy: 0.9721\n",
            "Epoch 5/20\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0468 - accuracy: 0.9668 - val_loss: 0.0455 - val_accuracy: 0.9756\n",
            "Epoch 6/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0472 - accuracy: 0.9712 - val_loss: 0.0497 - val_accuracy: 0.9721\n",
            "Epoch 7/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0459 - accuracy: 0.9616 - val_loss: 0.0507 - val_accuracy: 0.9512\n",
            "Epoch 8/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0453 - accuracy: 0.9581 - val_loss: 0.0498 - val_accuracy: 0.9721\n",
            "Epoch 9/20\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0447 - accuracy: 0.9677 - val_loss: 0.0494 - val_accuracy: 0.9721\n",
            "Epoch 10/20\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0444 - accuracy: 0.9782 - val_loss: 0.0489 - val_accuracy: 0.9721\n",
            "Epoch 11/20\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0459 - accuracy: 0.9642 - val_loss: 0.0489 - val_accuracy: 0.9512\n",
            "Epoch 12/20\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0454 - accuracy: 0.9694 - val_loss: 0.0490 - val_accuracy: 0.9721\n",
            "Epoch 13/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0453 - accuracy: 0.9598 - val_loss: 0.0497 - val_accuracy: 0.9512\n",
            "Epoch 14/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0451 - accuracy: 0.9642 - val_loss: 0.0488 - val_accuracy: 0.9721\n",
            "Epoch 15/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0440 - accuracy: 0.9747 - val_loss: 0.0477 - val_accuracy: 0.9721\n",
            "Epoch 16/20\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0455 - accuracy: 0.9747 - val_loss: 0.0481 - val_accuracy: 0.9721\n",
            "Epoch 17/20\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0455 - accuracy: 0.9651 - val_loss: 0.0490 - val_accuracy: 0.9721\n",
            "Epoch 18/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0446 - accuracy: 0.9729 - val_loss: 0.0485 - val_accuracy: 0.9721\n",
            "Epoch 19/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0455 - accuracy: 0.9598 - val_loss: 0.0487 - val_accuracy: 0.9721\n",
            "Epoch 20/20\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0445 - accuracy: 0.9694 - val_loss: 0.0484 - val_accuracy: 0.9721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO7LldMZA-TC",
        "outputId": "47e26ada-f717-4572-cebb-0cd19fa5e2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "_, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0590 - accuracy: 0.9638\n",
            "Test Accuracy: 0.9637883305549622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY5Sn6WilV3-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}