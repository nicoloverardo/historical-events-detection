{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('base': conda)",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "75e1510848ff81b2a8a3022c3bfac472ed28a49a56e1422a056d525171f2408b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# NER on Wiki dataset using Histo NER model (Glove)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf2crf pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/mhc/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/content/drive/My Drive/Colab Notebooks/mhc/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from model import BilstmCrf\n",
    "from text import PreProcessing\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)"
   ]
  },
  {
   "source": [
    "## Pre-processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Apply NER to wiki sentences using Spacy NER and our TensorFlow 2 model trained on Histo dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/wiki/wiki.csv\", sep=\"|\")\n",
    "df.Abstract = df.Abstract.parallel_apply(lambda x: PreProcessing.small_clean(x))\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data):\n",
    "    sentences, labels, sentence, tag = [], [], [], []\n",
    "\n",
    "    for text in data:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        for sent in doc.sents:\n",
    "            for word in sent:\n",
    "                sentence.append(word.text)\n",
    "                if word.ent_type_ is not \"\":\n",
    "                    tag.append(word.ent_type_)\n",
    "                else:\n",
    "                    tag.append(word.ent_iob_)\n",
    "        \n",
    "            sentences.append(\" \".join(sentence))\n",
    "            labels.append(\" \".join(tag))\n",
    "\n",
    "            sentence, tag = [], []\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = parse_data(tqdm(df.Abstract.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"data/wiki/wiki.pkl\").open(\"wb\") as f:\n",
    "    pickle.dump((X, y), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"data/wiki/wiki.pkl\").open(\"rb\") as f:\n",
    "    X, y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"data/histo/gloveemb.npz\")['embeddings']\n",
    "model = BilstmCrf()\n",
    "\n",
    "model.restore_model(embeddings, \"serialized/glove/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X, print=False)"
   ]
  },
  {
   "source": [
    "Map both predictions to the same labels and save them to disk"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_spacy = {\n",
    "    \"PERSON\": \"O\",\n",
    "    \"NORP\": \"O\",\n",
    "    \"FAC\": \"O\",\n",
    "    \"ORG\": \"O\",\n",
    "    \"GPE\": \"O\",\n",
    "    \"LOC\": \"O\",\n",
    "    \"PRODUCT\": \"O\",\n",
    "    \"WORK_OF_ART\": \"O\",\n",
    "    \"LAW\": \"O\",\n",
    "    \"LANGUAGE\": \"O\",\n",
    "    \"PERCENT\": \"O\",\n",
    "    \"MONEY\": \"O\",\n",
    "    \"QUANTITY\": \"O\",\n",
    "    \"CARDINAL\": \"O\",\n",
    "    \"ORDINAL\": \"O\",\n",
    "    \"O\": \"O\",\n",
    "    \"EVENT\": \"EVENT\",\n",
    "    \"TIME\": \"TIME\",\n",
    "    \"DATE\": \"DATE\"\n",
    "}\n",
    "\n",
    "mapping_histo = {\n",
    "    \"AUTHORITYLAW\": \"O\",\n",
    "    \"CLOTHES\": \"O\",\n",
    "    \"COMMUNICATION\": \"O\",\n",
    "    \"EDUCATION\": \"O\",\n",
    "    \"EMOTIONSEVALUATIONS\": \"O\",\n",
    "    \"ENTERTAINMENTART\": \"O\",\n",
    "    \"ENVIRONMENT\": \"O\",\n",
    "    \"FAITH\": \"O\",\n",
    "    \"FOODFARMING\": \"O\",\n",
    "    \"LIFEHEALTH\": \"O\", \n",
    "    \"MATTER\": \"O\",\n",
    "    \"MEASURE\": \"O\", \n",
    "    \"MENTAL\": \"O\", \n",
    "    \"O\": \"O\",\n",
    "    \"PHYSICALSENSATIONS\": \"O\", \n",
    "    \"POSSESSION\": \"O\", \n",
    "    \"SOCIAL\": \"O\",\n",
    "    \"SPACEMOVEMENT\": \"O\", \n",
    "    \"TRADEWORK\": \"O\",\n",
    "    \"EXISTENCECAUSATION\": \"EVENT\", \n",
    "    \"HOSTILITY\": \"EVENT\",\n",
    "    \"TIME\": \"TIME\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_spacy, y_mapped = [], []\n",
    "\n",
    "for i, sent in enumerate(X):\n",
    "    x = X[i].strip().split()\n",
    "    lbl = y[i].strip().split()\n",
    "\n",
    "    tmp = []\n",
    "    for j, word in enumerate(x):\n",
    "        \n",
    "        if lbl[j] in mapping_spacy.keys():\n",
    "            tmp.append((x[j], mapping_spacy[lbl[j]]))\n",
    "            y_mapped.append(mapping_spacy[lbl[j]])\n",
    "        else:\n",
    "            tmp.append((x[j], \"O\"))\n",
    "            y_mapped.append(\"O\")\n",
    "        \n",
    "    preds_spacy.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_flat, preds_histo = [], []\n",
    "for sent in preds:\n",
    "    tmp = []\n",
    "    for word, lbl in sent:\n",
    "        lbl_ = \"O\" if lbl is \"\" else lbl\n",
    "        lbl_ = lbl_.replace(\"B-\", \"\").replace(\"I-\", \"\")\n",
    "        \n",
    "        if lbl_ in mapping_histo.keys():\n",
    "            preds_flat.append(mapping_histo[lbl_])\n",
    "            tmp.append((word, mapping_histo[lbl_]))\n",
    "        else:\n",
    "            preds_flat.append(\"O\")\n",
    "            tmp.append((word, \"O\"))\n",
    "        \n",
    "    preds_histo.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"data/wiki/preds_histo.pkl\").open(\"wb\") as f:\n",
    "    pickle.dump(preds_histo, f)\n",
    "\n",
    "with Path(\"data/wiki/preds_spacy.pkl\").open(\"wb\") as f:\n",
    "    pickle.dump(preds_spacy, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"data/wiki/preds_spacy.pkl\").open(\"rb\") as f:\n",
    "    preds_spacy = pickle.load(f)\n",
    "\n",
    "with Path(\"data/wiki/preds_histo.pkl\").open(\"rb\") as f:\n",
    "    preds_histo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n        DATE       0.00      0.00      0.00      9963\n       EVENT       0.03      0.03      0.03      4507\n           O       0.94      0.97      0.96    247158\n        TIME       0.00      0.00      0.00       367\n\n    accuracy                           0.92    261995\n   macro avg       0.24      0.25      0.25    261995\nweighted avg       0.89      0.92      0.90    261995\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_mapped, preds_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_for_spacyviz(data):\n",
    "    sp_preds = []\n",
    "    for sent in data:\n",
    "        ent_sent = {}\n",
    "        ents = []\n",
    "        str_sent = \"\"\n",
    "\n",
    "        for word, lbl in sent:\n",
    "            if lbl is not \"O\":\n",
    "                start = len(str_sent)\n",
    "                end = start + len(word)\n",
    "                ents.append({\"start\": start, \"end\": end, \"label\": lbl})\n",
    "\n",
    "            str_sent = str_sent + word + \" \"\n",
    "        \n",
    "        ents = merge_ents(ents) if len(ents) > 0 else ents \n",
    "    \n",
    "        sp_preds.append({\"text\": str_sent.strip(), \"ents\": ents, \"title\": None})\n",
    "\n",
    "    return sp_preds\n",
    "\n",
    "def merge_ents(ents):\n",
    "    ents_ = []\n",
    "    for i, e in enumerate(ents):\n",
    "        if i != 0:\n",
    "            if ents[i-1][\"end\"] + 1 == ents[i][\"start\"] and ents[i-1][\"label\"] == ents[i][\"label\"]:\n",
    "                ents_[-1][\"end\"] = ents[i][\"end\"]\n",
    "            else:\n",
    "                ents_.append(ents[i])\n",
    "        else:\n",
    "            ents_.append(ents[i])\n",
    "    \n",
    "    return ents_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(0, len(preds_histo), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_preds_histo = convert_for_spacyviz([preds_histo[i] for i in r])\n",
    "sp_preds_spacy = convert_for_spacyviz([preds_spacy[i] for i in r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The skirmish \n<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    was\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n</mark>\n the first \n<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    armed conflict\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n</mark>\n of the First Opium \n<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    War\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n</mark>\n and \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    occurred\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n</mark>\n when British boats opened \n<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    fire\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n</mark>\n on Chinese \n<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    war\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n</mark>\n junks enforcing food sales embargo on the British community</div>\n\n<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The kneecaps of Ajax \n<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    were\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n</mark>\n exactly the size of discus for the boy pentathlon</div>\n\n<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">They resulted in the incorporation of Saxony into the Frankish realm and their forcible conversion from Germanic paganism to CatholicismThe Saxons were \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    divided\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n</mark>\n into four subgroups in four regions Nearest to the ancient Frankish kingdom of Austrasia was</div></span>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "displacy.render(sp_preds_histo, style=\"ent\", jupyter=True, manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The skirmish was the first armed conflict of \n<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    the First Opium War\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n</mark>\n and occurred when British boats opened fire on Chinese war junks enforcing food sales embargo on the British community</div>\n\n<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The kneecaps of Ajax were exactly the size of discus for the boy pentathlon</div>\n\n<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">They resulted in the incorporation of Saxony into the Frankish realm and their forcible conversion from Germanic paganism to CatholicismThe Saxons were divided into four subgroups in four regions Nearest to the ancient Frankish kingdom of Austrasia was</div></span>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "displacy.render(sp_preds_spacy, style=\"ent\", jupyter=True, manual=True)"
   ]
  }
 ]
}